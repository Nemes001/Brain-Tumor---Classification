{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2068723a",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "# Training + Validation split (80/20)\n",
    "train_ds = tf.keras.utils.image_dataset_from_directory(\n",
    "    r\"D:\\DataSET\\Training\",\n",
    "    image_size=(512, 512),\n",
    "    batch_size=16,\n",
    "    validation_split=0.2,   # 20% for validation\n",
    "    subset=\"training\",\n",
    "    seed=123\n",
    ")\n",
    "\n",
    "val_ds = tf.keras.utils.image_dataset_from_directory(\n",
    "    r\"D:\\DataSET\\Training\",\n",
    "    image_size=(512, 512),\n",
    "    batch_size=16,\n",
    "    validation_split=0.2,\n",
    "    subset=\"validation\",\n",
    "    seed=123\n",
    ")\n",
    "\n",
    "# Testing dataset\n",
    "test_ds = tf.keras.utils.image_dataset_from_directory(\n",
    "    r\"D:\\DataSET\\Testing\",\n",
    "    image_size=(512, 512),\n",
    "    batch_size=16\n",
    ")\n",
    "\n",
    "# Normalize pixel values\n",
    "train_ds = train_ds.map(lambda x, y: (x/255.0, y))\n",
    "val_ds   = val_ds.map(lambda x, y: (x/255.0, y))\n",
    "test_ds  = test_ds.map(lambda x, y: (x/255.0, y))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de3deae3",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "#Pure LSTM Model : Model1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec117457",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "from tensorflow.keras import layers, models\n",
    "\n",
    "# Pure LSTM model\n",
    "def build_lstm_model(input_shape=(512,512,3), num_classes=4):\n",
    "    inputs = layers.Input(shape=input_shape)\n",
    "    x = layers.Reshape((512, 512*3))(inputs)   # treat each row as a timestep\n",
    "    x = layers.LSTM(256, return_sequences=True)(x)\n",
    "    x = layers.Dropout(0.3)(x)\n",
    "    x = layers.LSTM(128)(x)\n",
    "    x = layers.Dropout(0.3)(x)\n",
    "    outputs = layers.Dense(num_classes, activation='softmax')(x)\n",
    "    model = models.Model(inputs, outputs, name=\"LSTM_only\")\n",
    "    return model\n",
    "\n",
    "# Build and compile\n",
    "model1 = build_lstm_model()\n",
    "model1.compile(optimizer='adam',\n",
    "               loss='sparse_categorical_crossentropy',\n",
    "               metrics=['accuracy'])\n",
    "\n",
    "# Train & evaluate\n",
    "history1 = model1.fit(train_ds, epochs=10, validation_data=val_ds, verbose=1)\n",
    "loss1, acc1 = model1.evaluate(test_ds, verbose=1)\n",
    "print(f\"Model1 (LSTM-only) Test Accuracy: {acc1:.2f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "493b848a",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "#Pure CBAM Model : Model2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce65158a",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras import layers, models\n",
    "\n",
    "# CBAM block\n",
    "def cbam_block(feature_map, ratio=8):\n",
    "    channel = feature_map.shape[-1]\n",
    "\n",
    "    # Channel Attention\n",
    "    shared_dense_one = layers.Dense(channel // ratio, activation='relu')\n",
    "    shared_dense_two = layers.Dense(channel)\n",
    "\n",
    "    avg_pool = layers.GlobalAveragePooling2D()(feature_map)\n",
    "    avg_pool = layers.Reshape((1,1,channel))(avg_pool)\n",
    "    avg_pool = shared_dense_two(shared_dense_one(avg_pool))\n",
    "\n",
    "    max_pool = layers.GlobalMaxPooling2D()(feature_map)\n",
    "    max_pool = layers.Reshape((1,1,channel))(max_pool)\n",
    "    max_pool = shared_dense_two(shared_dense_one(max_pool))\n",
    "\n",
    "    channel_attention = layers.Activation('sigmoid')(avg_pool + max_pool)\n",
    "    channel_refined = layers.multiply([feature_map, channel_attention])\n",
    "\n",
    "    # Spatial Attention\n",
    "    avg_pool = layers.Lambda(lambda x: tf.reduce_mean(x, axis=-1, keepdims=True))(channel_refined)\n",
    "    max_pool = layers.Lambda(lambda x: tf.reduce_max(x, axis=-1, keepdims=True))(channel_refined)\n",
    "    concat = layers.Concatenate(axis=-1)([avg_pool, max_pool])\n",
    "    spatial_attention = layers.Conv2D(1, kernel_size=7, padding='same', activation='sigmoid')(concat)\n",
    "\n",
    "    refined_feature = layers.multiply([channel_refined, spatial_attention])\n",
    "    return refined_feature\n",
    "\n",
    "# Deep CBAM branch with proper residuals\n",
    "def build_cbam_branch(input_shape=(512,512,3)):\n",
    "    inputs = layers.Input(shape=input_shape)\n",
    "\n",
    "    # Block 1\n",
    "    x = layers.Conv2D(32, (3,3), activation='relu', padding='same')(inputs)\n",
    "    x = layers.MaxPooling2D((2,2))(x)\n",
    "    x = cbam_block(x)\n",
    "\n",
    "    # Block 2 with residual projection\n",
    "    skip = x\n",
    "    x = layers.Conv2D(64, (3,3), activation='relu', padding='same')(x)\n",
    "    x = layers.MaxPooling2D((2,2))(x)\n",
    "    x = cbam_block(x)\n",
    "    skip = layers.Conv2D(64, (1,1), strides=(2,2), padding='same')(skip)\n",
    "    x = layers.Add()([x, skip])\n",
    "\n",
    "    # Block 3 with residual projection\n",
    "    skip = x\n",
    "    x = layers.Conv2D(128, (3,3), activation='relu', padding='same')(x)\n",
    "    x = layers.MaxPooling2D((2,2))(x)\n",
    "    x = cbam_block(x)\n",
    "    skip = layers.Conv2D(128, (1,1), strides=(2,2), padding='same')(skip)\n",
    "    x = layers.Add()([x, skip])\n",
    "\n",
    "    # Block 4 (extra depth, no residual)\n",
    "    x = layers.Conv2D(256, (3,3), activation='relu', padding='same')(x)\n",
    "    x = layers.MaxPooling2D((2,2))(x)\n",
    "    x = cbam_block(x)\n",
    "\n",
    "    # Global pooling\n",
    "    x = layers.GlobalAveragePooling2D()(x)\n",
    "\n",
    "    return models.Model(inputs, x, name=\"Deep_CBAM_branch\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b31f1438",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "model2 = build_cbam_branch(input_shape=(512,512,3))\n",
    "outputs2 = layers.Dense(4, activation='softmax')(model2.output)\n",
    "model2 = models.Model(model2.input, outputs2, name=\"Deep_CBAM\")\n",
    "\n",
    "model2.compile(optimizer='adam', loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n",
    "history2 = model2.fit(train_ds, epochs=10, validation_data=val_ds, verbose=1)\n",
    "loss2, acc2 = model2.evaluate(test_ds, verbose=1)\n",
    "print(f\"Model2 (Deep CBAM) Test Accuracy: {acc2:.2f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2caa7829",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "#Final LSTM + CBAM : Model3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e228649",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "# Remove the final softmax layer from each model\n",
    "lstm_feature_extractor = models.Model(\n",
    "    inputs=model1.input,\n",
    "    outputs=model1.layers[-2].output,  # penultimate layer\n",
    "    name=\"LSTM_features\"\n",
    ")\n",
    "\n",
    "cbam_feature_extractor = models.Model(\n",
    "    inputs=model2.input,\n",
    "    outputs=model2.layers[-2].output,  # penultimate layer\n",
    "    name=\"CBAM_features\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a0522cc",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "# Shared input\n",
    "inputs = layers.Input(shape=(512,512,3))\n",
    "\n",
    "# Get features from both models\n",
    "lstm_features = lstm_feature_extractor(inputs)\n",
    "cbam_features = cbam_feature_extractor(inputs)\n",
    "\n",
    "# Concatenate feature vectors\n",
    "concat = layers.Concatenate()([lstm_features, cbam_features])\n",
    "\n",
    "# Classification head\n",
    "x = layers.Dense(128, activation='relu')(concat)\n",
    "x = layers.Dropout(0.3)(x)\n",
    "outputs = layers.Dense(4, activation='softmax')(x)\n",
    "\n",
    "# Final hybrid model\n",
    "model3 = models.Model(inputs=inputs, outputs=outputs, name=\"Hybrid_LSTM_CBAM\")\n",
    "\n",
    "# Compile\n",
    "model3.compile(optimizer='adam',\n",
    "               loss='sparse_categorical_crossentropy',\n",
    "               metrics=['accuracy'])\n",
    "\n",
    "model3.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "05ebc4cd",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "history3 = model3.fit(train_ds, epochs=10, validation_data=val_ds, verbose=1)\n",
    "loss3, acc3 = model3.evaluate(test_ds, verbose=1)\n",
    "print(f\"Model3 (Hybrid LSTM+CBAM) Test Accuracy: {acc3:.2f}\")"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
